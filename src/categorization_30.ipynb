{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam-39/abbreviation-identification/blob/main/src/categorization_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VGz2VVAjoka"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKZALXq6jokg"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJfSONsmknw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6bb591-5a98-41fe-ee38-6e2858e7ec77"
      },
      "source": [
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q tensorflow_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 12.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegzWctzjokh"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmm2OWYLzaMq",
        "outputId": "9203dc37-d4dc-486e-92cd-f3e78a51344b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTTSA2cf4EO9"
      },
      "source": [
        "path='/content/drive/MyDrive/Colab Notebooks/full_data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-G8B0Nqjoki"
      },
      "source": [
        "data = pd.read_csv(path,nrows=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrDzPHgpsEC"
      },
      "source": [
        "# data2 = pd.read_csv(path, nrows=3000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbnSTY3Gp0Ez"
      },
      "source": [
        "# len(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CgoXc8wjoki",
        "outputId": "7d46578e-b2f5-4315-9280-70b028004aab"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "vA1xsAMXHWTD",
        "outputId": "782f8b48-c3ef-4022-e606-a1549fd6acaf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04c3b292-ffa4-49d5-852d-73144ceec535\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>alphabisabolol has a primary antipeptic action...</td>\n",
              "      <td>56</td>\n",
              "      <td>substrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a report is given on the recent discovery of o...</td>\n",
              "      <td>24|49|68|113|137|172</td>\n",
              "      <td>carcinosarcoma|recovery|reference|recovery|aft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the virostatic compound nndiethyloxotetradecyl...</td>\n",
              "      <td>55</td>\n",
              "      <td>substrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rmi rmi and rmi are newly synthetized nrdibenz...</td>\n",
              "      <td>25|82|127|182|222</td>\n",
              "      <td>compounds|compounds|inhibitory|lethal doses|ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a doubleblind study with intraindividual compa...</td>\n",
              "      <td>22|26|28|77|90|144|158|203</td>\n",
              "      <td>oxazepam|placebo|oral administration|pentagast...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04c3b292-ffa4-49d5-852d-73144ceec535')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04c3b292-ffa4-49d5-852d-73144ceec535 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04c3b292-ffa4-49d5-852d-73144ceec535');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                TEXT  ...                                              LABEL\n",
              "0  alphabisabolol has a primary antipeptic action...  ...                                          substrate\n",
              "1  a report is given on the recent discovery of o...  ...  carcinosarcoma|recovery|reference|recovery|aft...\n",
              "2  the virostatic compound nndiethyloxotetradecyl...  ...                                          substrate\n",
              "3  rmi rmi and rmi are newly synthetized nrdibenz...  ...  compounds|compounds|inhibitory|lethal doses|ca...\n",
              "4  a doubleblind study with intraindividual compa...  ...  oxazepam|placebo|oral administration|pentagast...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "xs4lvzw3HWA8",
        "outputId": "0e670c06-c059-441a-95f8-a7e76177c5fa"
      },
      "source": [
        "data['TEXT'][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rmi rmi and rmi are newly synthetized nrdibenzobfoxepinylnmethylpiperazinemaleates which show interesting psychopharmacologic effects this work contains the results of a study performed with these three EDC in order to demonstrate their neuropsycholeptic activity in comparison with chloropromazine cpz and chlordiazepoxide cpd the inhibition of motility observed in mice shows that the compounds reduce the normal spontaneous motility as well as the muscle tone the centraldepressant activity is evidenced by increased barbiturateinduced sleep and a remarkable eyelid ptosis can also be observed our EDC do not show any activity on electroshock just as do cpz and cpd as to the antipsychotic outline our compounds show strong reduction of lethality due to amphetamine in grouped mice and a strong antiapomorphine activity they show also an antiaggressive effect and an GABA activity on avoidance behaviour much stronger than cpz we have also found extrapyramidal effects as catalepsy common to many tranquillizers of the kind of the standards used by us as for vegetative phenomena the compounds show hypotensive dose related action ranging from moderate to strong probably due to an areceptor inhibition adrenolytic activity against MLD of adrenaline antiserotonin and antihistaminic effects as well as other actions hypothermia analgesia etc confirm that rmi rmi and rmi are endowed with pharmacologic properties similar and more potent than those of cpz studies on the metabolism of brain CAs show that they are similar to cpz although with less effect on dopamine level'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wHA14QlDKta3",
        "outputId": "aa229d16-a491-435c-b052-46dae44e2d9b"
      },
      "source": [
        "data['LABEL'][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'compounds|compounds|inhibitory|lethal doses|catecholamines'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOWPFXjeKtYN",
        "outputId": "868a8786-f590-4a34-eaa8-d288471c4342"
      },
      "source": [
        "words = data['TEXT'][3].split()\n",
        "abrr_label = data['LABEL'][3].split('|')\n",
        "nums = data['LOCATION'][3].split('|')\n",
        "nums = [int(i) for i in nums]\n",
        "for i in range(len(nums)):\n",
        "    print(words[nums[i]]+\" \"+abrr_label[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDC compounds\n",
            "EDC compounds\n",
            "GABA inhibitory\n",
            "MLD lethal doses\n",
            "CAs catecholamines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5BB5C0ZKtV6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs4XeHznVV5s"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvPfEP-qVV23"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCp1krOkVV01"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ns3sNeVVyT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcvO7hwvKtTY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Maim0Cu1KtRW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vsENEBOjokl",
        "outputId": "63af0b72-76fb-4902-db24-cc9f03298ed7"
      },
      "source": [
        "final_data = data.sample(frac = 1)\n",
        "len(final_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeModdBDjokm",
        "outputId": "5b46cbc2-a843-43b5-f1a5-fdcf9274a02a"
      },
      "source": [
        "final_data = final_data[:65000]\n",
        "len(final_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbnIuoFzjokn"
      },
      "source": [
        "data_train = final_data[:60000]\n",
        "data_test = final_data[60000:65000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyiKSue8jokp",
        "outputId": "3eb863cc-3301-4adc-8322-7737fad7444f"
      },
      "source": [
        "print(data_train.shape)\n",
        "print(data_test.shape)\n",
        "print(final_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 3)\n",
            "(5000, 3)\n",
            "(65000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWr_HAbTeErh"
      },
      "source": [
        "dic = {}\n",
        "for i in range(len(final_data)):\n",
        "    words = data['LABEL'][i].split('|')\n",
        "    for word in words:\n",
        "        if word in dic:\n",
        "            dic[word]+=1\n",
        "        else:\n",
        "            dic[word]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZxL_d6feEou",
        "outputId": "df4eb3b0-79b9-4ad4-9f66-f33a79843929"
      },
      "source": [
        "import operator\n",
        "sorted_d = sorted(dic.items(), key=operator.itemgetter(1),reverse=True)\n",
        "sorted_d[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('after', 8255)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol6uXE3aeElN"
      },
      "source": [
        "top_20 = []\n",
        "for i in range(20):\n",
        "    top_20.append(sorted_d[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoS07A-feEh1"
      },
      "source": [
        "# top_20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtOLfsieEen"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucgsISf4eEbp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSX19IYeEWe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-u64SeeEH4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN6JM3utjokq"
      },
      "source": [
        "data_train.reset_index(drop = True, inplace = True)\n",
        "data_test.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chb-OAKIjokr",
        "outputId": "0441b331-e3c9-4cd2-d692-4ba66867cc15"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qu-oQ0tkira"
      },
      "source": [
        "# stop_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uxIf_upkiZc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "5XrzZ2rY5Vzs",
        "outputId": "fab50f33-6bde-4fff-b178-4768aa45a233"
      },
      "source": [
        "data_test.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we conducted a doubleblind comparative study o...</td>\n",
              "      <td>83|93|106</td>\n",
              "      <td>after|terbinafine|griseofulvin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a CS of plasmodium vivax from thailand with a ...</td>\n",
              "      <td>1|49|65|67</td>\n",
              "      <td>strain|intact|infected|feeding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>differentiated hl granulocytes were used to st...</td>\n",
              "      <td>65|71|183</td>\n",
              "      <td>release|membranes|peptides</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a cultivation system has been developed for pe...</td>\n",
              "      <td>80|92|120|161|196|207</td>\n",
              "      <td>after|branch|plasma membrane|plasma membrane|d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chronic nonspecific diarrhea cnsd is the most ...</td>\n",
              "      <td>63|119</td>\n",
              "      <td>groups|symptoms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the data to be discussed in this paper are dra...</td>\n",
              "      <td>28|54|114|153</td>\n",
              "      <td>preterm|study|preterm|development</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>three alternative methods for the screening of...</td>\n",
              "      <td>14|142|153|157|200</td>\n",
              "      <td>preparations|evaluation|assay|assay|behavior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nuclear sections of basalioma cells nuclear se...</td>\n",
              "      <td>54</td>\n",
              "      <td>tumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>this article intends to present goals tasks an...</td>\n",
              "      <td>54</td>\n",
              "      <td>development</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>almost all patients with cataplectic narcoleps...</td>\n",
              "      <td>58</td>\n",
              "      <td>study</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                TEXT  ...                                              LABEL\n",
              "0  we conducted a doubleblind comparative study o...  ...                     after|terbinafine|griseofulvin\n",
              "1  a CS of plasmodium vivax from thailand with a ...  ...                     strain|intact|infected|feeding\n",
              "2  differentiated hl granulocytes were used to st...  ...                         release|membranes|peptides\n",
              "3  a cultivation system has been developed for pe...  ...  after|branch|plasma membrane|plasma membrane|d...\n",
              "4  chronic nonspecific diarrhea cnsd is the most ...  ...                                    groups|symptoms\n",
              "5  the data to be discussed in this paper are dra...  ...                  preterm|study|preterm|development\n",
              "6  three alternative methods for the screening of...  ...       preparations|evaluation|assay|assay|behavior\n",
              "7  nuclear sections of basalioma cells nuclear se...  ...                                              tumor\n",
              "8  this article intends to present goals tasks an...  ...                                        development\n",
              "9  almost all patients with cataplectic narcoleps...  ...                                              study\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEGRGvIMjokr"
      },
      "source": [
        "sentences_train = []\n",
        "abber_locs_train = []\n",
        "abber_category_train = []\n",
        "\n",
        "sentences_test = []\n",
        "abber_locs_test = []\n",
        "abber_category_test = []\n",
        "\n",
        "for i in range(0, len(data_train)):\n",
        "    sentences_train.append(data_train['TEXT'][i])\n",
        "    abber_locs_train.append(data_train['LOCATION'][i].split(\"|\"))\n",
        "    abber_category_train.append(data_train['LABEL'][i].split(\"|\"))\n",
        "    \n",
        "for i in range(0, len(data_test)):\n",
        "    sentences_test.append(data_test['TEXT'][i])\n",
        "    abber_locs_test.append(data_test['LOCATION'][i].split(\"|\"))\n",
        "    abber_category_test.append(data_test['LABEL'][i].split(\"|\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "_5X1jruYMTIG",
        "outputId": "459fab1a-a78b-41aa-c59f-b94391a0eeb4"
      },
      "source": [
        "sentences_test[9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'almost all patients with cataplectic narcolepsy are drpositive it has been suggested that the nondr allelehaplotype might not be neutral with respect to disease susceptibility it has also been reported that taq i dqa and bam hi eco ri eco rv and pst i dqb restriction fragments might differentiate between narcoleptic and healthy drpositive individuals in the present T0 hla class ii gene polymorphisms were investigated by restriction fragment length polymorphism rflp analysis in swedish patients with cataplectic narcolepsy random controls and drassociated homozygous cell lines all patients had taq i drbdqadqb patterns corresponding to the drwdqwdw haplotype the nondr haplotype was found to be neutral this genotyped group of patients allows firm rejection of a recessive mode of inheritance and supports a dominant or additive model no dqa or dqb rflps were found that could differentiate between drpositive narcoleptics drwdqwdwpositive controls or dwhomozygous cell lines no significant msp i hladp association was found no linkage disequilibrium was observed between the drwdqwdw haplotype and alleles of the dp subregion in patients or controls thus the hlad regionassociated narcolepsy susceptibility gene may be located telomeric to the hladp subregion no rflps have been observed that can locate the narcolepsy susceptibility gene closer to the dq than to the dr subregion'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWMgDht-MSzv",
        "outputId": "f62dee4b-f645-4d31-f6d5-2c6397b7e781"
      },
      "source": [
        "abber_locs_test[9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['58']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh5Gtdi9Mjdf",
        "outputId": "b57787d5-fd52-4e2d-f872-d57358ab9ba4"
      },
      "source": [
        "abber_category_test[9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['study']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF8FyBeE-v3V",
        "outputId": "79873397-618c-45f3-d5a2-307ec77d2bc2"
      },
      "source": [
        "print(len(sentences_test))\n",
        "print(len(abber_locs_test))\n",
        "print(len(abber_category_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n",
            "5000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek0U6RJ-6tfx"
      },
      "source": [
        "for i in range(len(abber_category_train)):\n",
        "    for j in range(len(abber_category_train[i])):\n",
        "        if abber_category_train[i][j] not in top_20:\n",
        "            abber_category_train[i][j]='-'\n",
        "\n",
        "for i in range(len(abber_category_test)):\n",
        "    for j in range(len(abber_category_test[i])):\n",
        "        if abber_category_test[i][j] not in top_20:\n",
        "            abber_category_test[i][j]='-'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ea5s5E7l81r",
        "outputId": "2140f993-5fc2-4d49-e102-020e7596835a"
      },
      "source": [
        "len(abber_locs_test[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV3_Sp2pl8dP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Srus7U7L73"
      },
      "source": [
        "x0 = []\n",
        "x1 = []\n",
        "x2 = []\n",
        "for i in range(len(abber_category_train)):\n",
        "    y0 = []\n",
        "    y1 = []\n",
        "    y2 = []\n",
        "    for j in range(len(abber_category_train[i])):\n",
        "        if abber_category_train[i][j]!='-':\n",
        "            y1.append(abber_locs_train[i][j])\n",
        "            y2.append(abber_category_train[i][j])\n",
        "    if len(y1)!=0:\n",
        "        x0.append(sentences_train[i])\n",
        "        x1.append(y1)\n",
        "        x2.append(y2)\n",
        "\n",
        "sentences_train = x0\n",
        "abber_locs_train = x1\n",
        "abber_category_train = x2\n",
        "\n",
        "\n",
        "x0 = []\n",
        "x1 = []\n",
        "x2 = []\n",
        "for i in range(len(abber_category_test)):\n",
        "    y0 = []\n",
        "    y1 = []\n",
        "    y2 = []\n",
        "    for j in range(len(abber_category_test[i])):\n",
        "        if abber_category_test[i][j]!='-':\n",
        "            y1.append(abber_locs_test[i][j])\n",
        "            y2.append(abber_category_test[i][j])\n",
        "    if len(y1)!=0:\n",
        "        x0.append(sentences_test[i])\n",
        "        x1.append(y1)\n",
        "        x2.append(y2)\n",
        "\n",
        "sentences_test = x0\n",
        "abber_locs_test = x1\n",
        "abber_category_test = x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRTNYnh8Mja5"
      },
      "source": [
        "Y_vec = []\n",
        "for label_vec in abber_category_train:\n",
        "    temp = []\n",
        "    for label in label_vec:\n",
        "        temp2 = [0]*20\n",
        "        for i in range(len(top_20)):\n",
        "            if label==top_20[i]:\n",
        "                temp2[i]=1\n",
        "        temp.append(temp2)\n",
        "    Y_vec.append(temp)\n",
        "\n",
        "Y_vec_test = []\n",
        "for label_vec in abber_category_test:\n",
        "    temp = []\n",
        "    for label in label_vec:\n",
        "        temp2 = [0]*20\n",
        "        for i in range(len(top_20)):\n",
        "            if label==top_20[i]:\n",
        "                temp2[i]=1\n",
        "        temp.append(temp2)\n",
        "    Y_vec_test.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1P_RczBABP-",
        "outputId": "82720e41-f7c7-4425-82b7-da567f981dd3"
      },
      "source": [
        "Y_vec_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOEQxtqFRc7S"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoW8h7dkwipK"
      },
      "source": [
        "# sentences_train\n",
        "# abber_locs_train\n",
        "# abber_category_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLdWXghUwilQ",
        "outputId": "07557f54-32e2-4b92-8601-ae6f77785d7a"
      },
      "source": [
        "abber_category_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['active']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kngPwZaQwiit",
        "outputId": "33b89ba2-3343-4b55-fff5-f2443847504e"
      },
      "source": [
        "avg = 0\n",
        "for sent in sentences_train:\n",
        "    disc = sent.split()\n",
        "    x = len(disc)\n",
        "    avg += x\n",
        "avg=avg/len(sentences_train)\n",
        "\n",
        "print(avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167.8995605102369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaLnqwDqwigz"
      },
      "source": [
        "fd_sentences = []\n",
        "fd_labels = []\n",
        "fd_words = []\n",
        "for i in range(len(sentences_train)):\n",
        "    words_vec = sentences_train[i].split()\n",
        "    sent_len = len(words_vec)\n",
        "    for j in range(len(abber_locs_train[i])):\n",
        "        pos = int(abber_locs_train[i][j])\n",
        "        if sent_len<128:\n",
        "            fd_sentences.append(\" \".join(words_vec))\n",
        "        elif pos<64:\n",
        "            fd_sentences.append(\" \".join(words_vec[:128]))\n",
        "        else:\n",
        "            fd_sentences.append(\" \".join(words_vec[pos-64:pos+63]))\n",
        "        fd_labels.append(abber_category_train[i][j])\n",
        "        fd_words.append(words_vec[pos])\n",
        "\n",
        "fd_sentences_test = []\n",
        "fd_labels_test = []\n",
        "fd_words_test = []\n",
        "for i in range(len(sentences_test)):\n",
        "    words_vec = sentences_test[i].split()\n",
        "    sent_len = len(words_vec)\n",
        "    for j in range(len(abber_locs_test[i])):\n",
        "        pos = int(abber_locs_test[i][j])\n",
        "        if sent_len<128:\n",
        "            fd_sentences_test.append(\" \".join(words_vec))\n",
        "        elif pos<64:\n",
        "            fd_sentences_test.append(\" \".join(words_vec[:128]))\n",
        "        else:\n",
        "            fd_sentences_test.append(\" \".join(words_vec[pos-64:pos+63]))\n",
        "        fd_labels_test.append(abber_category_test[i][j])\n",
        "        fd_words_test.append(words_vec[pos])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ2ksoyFwiei",
        "outputId": "3979696e-3bef-4a95-a63a-32196c1dfef6"
      },
      "source": [
        "print(len(fd_sentences_test))\n",
        "print(len(fd_labels_test))\n",
        "print(len(fd_words_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3634\n",
            "3634\n",
            "3634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4dBo0amx6d1"
      },
      "source": [
        "# print(fd_sentences.shape)\n",
        "# fd_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW6Nk6TwwicT",
        "outputId": "4965486d-1bfd-4e41-e01c-2b104a7ff6c5"
      },
      "source": [
        "for i in range(5):\n",
        "    print(fd_sentences[i])\n",
        "    print(fd_labels[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "days of age a control group cont remained with the mother in the nest during this time cold subjects were developmentally delayed and had lower body and brain weights than the other three groups into adulthood warm and agit subjects both maternally separated at nest temperature had significant growth delays compared to cont but grew more quickly than cold subjects cold subjects were less AS than the other maternally separated groups and warm and agit groups were more active activity did not differ at or days of age however AD warm subjects were less sensitive and cold subjects were more sensitive to amphetamine as measured by locomotor activity than cont and agit subjects who did not differ from each other the relationship between early stress changes in\n",
            "active\n",
            "region an open reading frame encoding the expected amino acid protein and an extensive nontranslated CS the ID of the clone as full length was consistent with results obtained in mrna blotting experiments using polya mrna from bovine heart the coding sequence was placed downstream of a bacteriophage t promoter and protein was expressed in e coli the expressed enzyme was soluble and catalytically AS and was readily isolated and purified the recombinant protein had the expected mr of estimated by sdspage and it showed crossreactivity with antisera that had been raised against both the bovine heart and the human placenta enzymes the amino acid CS of the NT region of the expressed protein showed that methionine had been removed resulting in a CS identical to that\n",
            "active\n",
            "twelve outbreaks of SH b virus hbv infection associated with hbv infected surgical HCWs surgeons one perfusion technician were reported between and in england wales and RNA ireland a total of infections was identified transmission rates ranged from one to nine per cent but were higher for patients who had undergone L1 surgical procedures the number of infections reported underestimates the total number of patients who will have acquired hbv infection from hbv INF surgeons during this period because subclinical infections will have been missed and other outbreaks may not have been recognised or reported\n",
            "major\n",
            "a gallbladder cannula suitable for chronic implantation in the dog is described the device is simple to operate inexpensive to construct durable and easy to implant with the cannula in place measurements of hepatic and biliary drug kinetics as well as enterohepatic CF in the awake nonstressed animal are possible minimal postoperative care is required T3 implantation of the device\n",
            "function\n",
            "a gallbladder cannula suitable for chronic implantation in the dog is described the device is simple to operate inexpensive to construct durable and easy to implant with the cannula in place measurements of hepatic and biliary drug kinetics as well as enterohepatic CF in the awake nonstressed animal are possible minimal postoperative care is required T3 implantation of the device\n",
            "after\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uLlP7gTwiZp"
      },
      "source": [
        "Y_vec = []\n",
        "for label in fd_labels:\n",
        "    temp = [0]*20\n",
        "    for i in range(len(top_20)):\n",
        "        if label==top_20[i]:\n",
        "            temp[i]=1\n",
        "    Y_vec.append(temp)\n",
        "\n",
        "Y_vec_test = []\n",
        "for label in fd_labels_test:\n",
        "    temp = [0]*20\n",
        "    for i in range(len(top_20)):\n",
        "        if label==top_20[i]:\n",
        "            temp[i]=1\n",
        "    Y_vec_test.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKLhjH1qwiXG",
        "outputId": "3b3d89e7-540a-4c09-f6cd-30ea622e49f0"
      },
      "source": [
        "len(Y_vec_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3634"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkjnkE7BRxua"
      },
      "source": [
        "Y_vec2 = []\n",
        "for label in fd_labels:\n",
        "    for i in range(len(top_20)):\n",
        "        if label==top_20[i]:\n",
        "            temp=i\n",
        "    Y_vec2.append(temp)\n",
        "\n",
        "Y_vec2_test = []\n",
        "for label in fd_labels_test:\n",
        "    for i in range(len(top_20)):\n",
        "        if label==top_20[i]:\n",
        "            temp=i\n",
        "    Y_vec2_test.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbbQlTfiSMVO",
        "outputId": "0f39b59e-44a2-4a69-f894-861904363991"
      },
      "source": [
        "Y_vec2_test[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ootBxhe7MjYb",
        "outputId": "959fb1cf-3c59-40bc-9327-f568f8ae5cdd"
      },
      "source": [
        "len(Y_vec2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3634"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p8hdNghjoks"
      },
      "source": [
        "abbers_train = []\n",
        "for i in range(0, len(abber_locs_train)):\n",
        "    temp_train = []\n",
        "    for l in abber_locs_train[i]:\n",
        "        temp_train.append(sentences_train[i].split()[int(l)])\n",
        "    abbers_train.append(temp_train)\n",
        "    \n",
        "abbers_test = []\n",
        "for i in range(0, len(abber_locs_test)):\n",
        "    temp_test = []\n",
        "    for l in abber_locs_test[i]:\n",
        "        temp_test.append(sentences_test[i].split()[int(l)])\n",
        "    abbers_test.append(temp_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV0ECX6Hjcwu",
        "outputId": "b689aabc-0530-4413-edab-e0cae84c3230"
      },
      "source": [
        "abbers_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AS']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIa-sSydjct1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VcUEeHjjcrz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aWpsyyWjWvu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AguHxSM-jokt"
      },
      "source": [
        "def select_words_train(sentence, abber_list):\n",
        "  j = 0\n",
        "  words = sentence.split()\n",
        "  random.shuffle(words)\n",
        "  temp = []\n",
        "  for i in range(0, len(words)):\n",
        "    if (words[i] in abber_list or words[i] in temp):\n",
        "      continue\n",
        "    else:\n",
        "      temp.append(words[i])\n",
        "      j += 1\n",
        "    if (j == (9*len(abber_list))):\n",
        "      break\n",
        "  return temp\n",
        "\n",
        "\n",
        "def select_words_test(sentence, abber_list):\n",
        "  j = 0\n",
        "  words = sentence.split()\n",
        "  random.shuffle(words)\n",
        "  temp = []\n",
        "  for i in range(0, len(words)):\n",
        "    if (words[i] in abber_list or words[i] in temp):\n",
        "      continue\n",
        "    else:\n",
        "      temp.append(words[i])\n",
        "      j += 1\n",
        "  return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFL2kTIQjokt"
      },
      "source": [
        "normal_words_train = []\n",
        "for i in range(0, len(sentences_train)):\n",
        "  normal_words_train.append(select_words_train(sentences_train[i], abbers_train[i]))\n",
        "\n",
        "normal_words_test = []\n",
        "for i in range(0, len(sentences_test)):\n",
        "  normal_words_test.append(select_words_test(sentences_test[i], abbers_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "9obQ8p--joku",
        "outputId": "34a7fb8e-5a51-4a49-80e2-f4df9586f930"
      },
      "source": [
        "sentences_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the first representative of a group of mammalian low molecular weight phosphotyrosyl protein phosphatases was cloned sequenced and expressed in escherichia coli using a mer oligonucleotide probe based on the amino acid sequence of the purified enzyme several overlapping cdna clones were isolated from a bovine HR cdna library a fulllength clone was obtained consisting of a bp noncoding region an open reading frame encoding the expected amino acid protein and an extensive nontranslated CS the ID of the clone as full length was consistent with results obtained in mrna blotting experiments using polya mrna from bovine heart the coding sequence was placed downstream of a bacteriophage t promoter and protein was expressed in e coli the expressed enzyme was soluble and catalytically AS and was readily isolated and purified the recombinant protein had the expected mr of estimated by sdspage and it showed crossreactivity with antisera that had been raised against both the bovine heart and the human placenta enzymes the amino acid CS of the NT region of the expressed protein showed that methionine had been removed resulting in a CS identical to that of the enzyme isolated from the bovine tissue with the exception that the nterminal alanine of the protein from tissue is acetylated a kinetically competent phosphoenzyme intermediate was trapped from a phosphatasecatalyzed reaction using p nmr the covalent intermediate was identified as a cysteinyl phosphate by analogy with the nomenclature used for serine esterases these enzymes may be called cysteine phosphatases'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g59Bz7D0joku"
      },
      "source": [
        "def text_cleaner(text):\n",
        "    new_string = str(text)\n",
        "    return new_string\n",
        "\n",
        "def abbreviation_cleaner(text):\n",
        "    new_string = str(text)\n",
        "    return new_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKr4pdRKjokv"
      },
      "source": [
        "cleaned_sentences_train = []\n",
        "cleaned_abbers_train = []\n",
        "cleaned_words_train = []\n",
        "\n",
        "cleaned_sentences_test = []\n",
        "cleaned_abbers_test = []\n",
        "cleaned_words_test = []\n",
        "\n",
        "for i in range(0, len(sentences_train)):\n",
        "  cleaned_sentences_train.append(text_cleaner(sentences_train[i]))\n",
        "\n",
        "for i in range(0, len(abbers_train)):\n",
        "  temp = []\n",
        "  for abber in abbers_train[i]:\n",
        "    temp.append(abbreviation_cleaner(abber))\n",
        "  cleaned_abbers_train.append(temp)\n",
        "\n",
        "for i in range(0, len(normal_words_train)):\n",
        "  temp = []\n",
        "  for word in normal_words_train[i]:\n",
        "    temp.append(abbreviation_cleaner(word))\n",
        "  cleaned_words_train.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0, len(sentences_test)):\n",
        "  cleaned_sentences_test.append(text_cleaner(sentences_test[i]))\n",
        "\n",
        "for i in range(0, len(abbers_test)):\n",
        "  temp = []\n",
        "  for abber in abbers_test[i]:\n",
        "    temp.append(abbreviation_cleaner(abber))\n",
        "  cleaned_abbers_test.append(temp)\n",
        "\n",
        "for i in range(0, len(normal_words_test)):\n",
        "  temp = []\n",
        "  for word in normal_words_test[i]:\n",
        "    temp.append(abbreviation_cleaner(word))\n",
        "  cleaned_words_test.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpBWhW3jokv"
      },
      "source": [
        "abber_vicinity_train = []\n",
        "for i in range(0, len(cleaned_sentences_train)):\n",
        "  list_of_words = cleaned_sentences_train[i].split()\n",
        "  vicinity_sentences = []\n",
        "  for abber in cleaned_abbers_train[i]:\n",
        "    # print(i)\n",
        "    index = list_of_words.index(abber)\n",
        "    lower_limit = max(0, index-4)\n",
        "    upper_limit = min(index + 4 + 1, len(list_of_words))\n",
        "    sentence = ' '.join(list_of_words[lower_limit:upper_limit]).strip()\n",
        "    vicinity_sentences.append(sentence)\n",
        "  abber_vicinity_train.append(vicinity_sentences)\n",
        "\n",
        "abber_vicinity_test = []\n",
        "for i in range(0, len(cleaned_sentences_test)):\n",
        "  list_of_words = cleaned_sentences_test[i].split()\n",
        "  vicinity_sentences = []\n",
        "  for abber in cleaned_abbers_test[i]:\n",
        "    # print(i)\n",
        "    index = list_of_words.index(abber)\n",
        "    lower_limit = max(0, index-4)\n",
        "    upper_limit = min(index + 4 + 1, len(list_of_words))\n",
        "    sentence = ' '.join(list_of_words[lower_limit:upper_limit]).strip()\n",
        "    vicinity_sentences.append(sentence)\n",
        "  abber_vicinity_test.append(vicinity_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA7h1XEdjokv"
      },
      "source": [
        "normal_words_vicinity_train = []\n",
        "for i in range(0, len(cleaned_sentences_train)):\n",
        "  list_of_words = cleaned_sentences_train[i].split()\n",
        "  vicinity_sentences = []\n",
        "  for word in cleaned_words_train[i]:\n",
        "    # print(i)\n",
        "    index = list_of_words.index(word)\n",
        "    lower_limit = max(0, index-4)\n",
        "    upper_limit = min(index + 4 + 1, len(list_of_words))\n",
        "    sentence = ' '.join(list_of_words[lower_limit:upper_limit]).strip()\n",
        "    vicinity_sentences.append(sentence)\n",
        "  normal_words_vicinity_train.append(vicinity_sentences)\n",
        "\n",
        "normal_words_vicinity_test = []\n",
        "for i in range(0, len(cleaned_sentences_test)):\n",
        "  list_of_words = cleaned_sentences_test[i].split()\n",
        "  vicinity_sentences = []\n",
        "  for word in cleaned_words_test[i]:\n",
        "    # print(i)\n",
        "    index = list_of_words.index(word)\n",
        "    lower_limit = max(0, index-4)\n",
        "    upper_limit = min(index + 4 + 1, len(list_of_words))\n",
        "    sentence = ' '.join(list_of_words[lower_limit:upper_limit]).strip()\n",
        "    vicinity_sentences.append(sentence)\n",
        "  normal_words_vicinity_test.append(vicinity_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m_kmTQtjokw",
        "outputId": "c671c3a2-647d-4ffa-e5e5-55d32de2b872"
      },
      "source": [
        "abber_vicinity_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['was soluble and catalytically AS and was readily isolated']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcBFAcIKjokx"
      },
      "source": [
        "final_normal_sentences_train = []\n",
        "final_normal_words_train = []\n",
        "for i in range(0, len(normal_words_vicinity_train)):\n",
        "  for j in range(0, len(normal_words_vicinity_train[i])):\n",
        "    final_normal_sentences_train.append(normal_words_vicinity_train[i][j])\n",
        "    final_normal_words_train.append(cleaned_words_train[i][j])\n",
        "    \n",
        "final_normal_sentences_test = []\n",
        "final_normal_words_test = []\n",
        "for i in range(0, len(normal_words_vicinity_test)):\n",
        "  for j in range(0, len(normal_words_vicinity_test[i])):\n",
        "    final_normal_sentences_test.append(normal_words_vicinity_test[i][j])\n",
        "    final_normal_words_test.append(cleaned_words_test[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOuEoCVEjokx"
      },
      "source": [
        "final_abber_sentences_train = []\n",
        "final_abber_words_train = []\n",
        "for i in range(0, len(abber_vicinity_train)):\n",
        "  for j in range(0, len(abber_vicinity_train[i])):\n",
        "    final_abber_sentences_train.append(abber_vicinity_train[i][j])\n",
        "    final_abber_words_train.append(cleaned_abbers_train[i][j])\n",
        "    \n",
        "final_abber_sentences_test = []\n",
        "final_abber_words_test = []\n",
        "for i in range(0, len(abber_vicinity_test)):\n",
        "  for j in range(0, len(abber_vicinity_test[i])):\n",
        "    final_abber_sentences_test.append(abber_vicinity_test[i][j])\n",
        "    final_abber_words_test.append(cleaned_abbers_test[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqljJMY4jokx"
      },
      "source": [
        "labels_train = []\n",
        "for i in range(0, len(final_normal_words_train)):\n",
        "  labels_train.append(0)\n",
        "for i in range(0, len(final_abber_words_train)):\n",
        "  labels_train.append(1)\n",
        "\n",
        "labels_test = []\n",
        "for i in range(0, len(final_normal_words_test)):\n",
        "  labels_test.append(0)\n",
        "for i in range(0, len(final_abber_words_test)):\n",
        "  labels_test.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYoknWFjoky"
      },
      "source": [
        "final_sentences_train = np.concatenate((np.array(final_normal_sentences_train), np.array(final_abber_sentences_train)), axis = 0)\n",
        "final_sentences_test = np.concatenate((np.array(final_normal_sentences_test), np.array(final_abber_sentences_test)), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERl6yUUTjoky"
      },
      "source": [
        "final_words_train = np.concatenate((np.array(final_normal_words_train), np.array(final_abber_words_train)), axis = 0)\n",
        "final_words_test = np.concatenate((np.array(final_normal_words_test), np.array(final_abber_words_test)), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0sI9rGZjoky"
      },
      "source": [
        "final_labels_train = np.array(labels_train)\n",
        "final_labels_test = np.array(labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "14q32Wzcjoky",
        "outputId": "9b05a516-86b3-43b9-df6d-8892aa57e614"
      },
      "source": [
        "final_sentences_train[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'during this time cold subjects were developmentally delayed and'"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra2hySo0rtiq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLEZ7GuQrcTl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v7s_w_MrcKH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6WKAzTOrcHN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoj0A36OrcEo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r8gNR30rcCD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP-F7976rb_3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OYZ001trb9Y"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4kfZD15rb7G"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXrqVVORjokz"
      },
      "source": [
        "final_data_train = pd.DataFrame({'sentences': fd_sentences, 'words': fd_words, 'labels': Y_vec2})\n",
        "final_data_test = pd.DataFrame({'sentences': fd_sentences_test, 'words': fd_words_test, 'labels': Y_vec2_test})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "NeUDkrrzo9BN",
        "outputId": "8dd27e33-1f54-43ea-d83d-0a98859e0ace"
      },
      "source": [
        "final_data_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>days of age a control group cont remained with...</td>\n",
              "      <td>AS</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>region an open reading frame encoding the expe...</td>\n",
              "      <td>AS</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twelve outbreaks of SH b virus hbv infection a...</td>\n",
              "      <td>L1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a gallbladder cannula suitable for chronic imp...</td>\n",
              "      <td>CF</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a gallbladder cannula suitable for chronic imp...</td>\n",
              "      <td>T3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences words  labels\n",
              "0  days of age a control group cont remained with...    AS       8\n",
              "1  region an open reading frame encoding the expe...    AS       8\n",
              "2  twelve outbreaks of SH b virus hbv infection a...    L1      17\n",
              "3  a gallbladder cannula suitable for chronic imp...    CF      11\n",
              "4  a gallbladder cannula suitable for chronic imp...    T3       0"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "3Pn7-6Wsjokz",
        "outputId": "8bdfc37b-7156-4096-ed89-7b5a17f64b34"
      },
      "source": [
        "final_data_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we conducted a doubleblind comparative study o...</td>\n",
              "      <td>T3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hl granulocytes were used to study the mechani...</td>\n",
              "      <td>PR</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spherical growth of spores was initiated by in...</td>\n",
              "      <td>T3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>segregation of the conidium from the phialide ...</td>\n",
              "      <td>SC</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chronic nonspecific diarrhea cnsd is the most ...</td>\n",
              "      <td>CG</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences words  labels\n",
              "0  we conducted a doubleblind comparative study o...    T3       0\n",
              "1  hl granulocytes were used to study the mechani...    PR      10\n",
              "2  spherical growth of spores was initiated by in...    T3       0\n",
              "3  segregation of the conidium from the phialide ...    SC      18\n",
              "4  chronic nonspecific diarrhea cnsd is the most ...    CG       7"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ueUckRtjokz"
      },
      "source": [
        "# for i in range(len(labels_test)):\n",
        "#     if label_test[i]==1:\n",
        "#         print(final_words_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "u9Zg1kPikJDi",
        "outputId": "035b7142-0427-4071-92dd-dbbc95f4d73c"
      },
      "source": [
        "final_data_train['sentences'][4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a gallbladder cannula suitable for chronic implantation in the dog is described the device is simple to operate inexpensive to construct durable and easy to implant with the cannula in place measurements of hepatic and biliary drug kinetics as well as enterohepatic CF in the awake nonstressed animal are possible minimal postoperative care is required T3 implantation of the device'"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0CMiY3HkJAt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YGrm61LkI-X"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bbvtAOUkI8H"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7JHp8hCkI5Q"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKqKg9mykI24"
      },
      "source": [
        "# type(final_data_train_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K05vPNd2jok0"
      },
      "source": [
        "# final_data_train['labels'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFBvuJCPjok1",
        "outputId": "2bf5178f-64c3-420b-cbcd-861891dcd67f"
      },
      "source": [
        "final_data_test['labels'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     716\n",
              "3     384\n",
              "2     345\n",
              "4     202\n",
              "7     197\n",
              "1     187\n",
              "5     174\n",
              "11    146\n",
              "6     143\n",
              "9     136\n",
              "19    125\n",
              "16    122\n",
              "15    119\n",
              "17    117\n",
              "14    110\n",
              "13    101\n",
              "8     100\n",
              "12     80\n",
              "10     79\n",
              "18     51\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdnj1s2xjok1"
      },
      "source": [
        "# Training the model on MeDal(train set) and testing on MeDal(test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b-uHoKMjok2"
      },
      "source": [
        "final_data_train['sentences'] = final_data_train['sentences'].apply(lambda x: str(x))\n",
        "final_data_train['words'] = final_data_train['words'].apply(lambda x: str(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqkMLdQZjok2"
      },
      "source": [
        "final_data_train_labels = list(final_data_train['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VaXJnq2jok3"
      },
      "source": [
        "final_data_train_labels = np.array(final_data_train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIF3NV0ujok3"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "preprocess_lnk = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "enc_lnk = 'https://tfhub.dev/google/experts/bert/pubmed/2'\n",
        "enc_lnk2 = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n",
        "\n",
        "bert_preprocessor = hub.load(preprocess_lnk)\n",
        "\n",
        "def make_classifier_model():\n",
        "  text_input1 = layers.Input(shape = (), dtype = tf.string, name = 'text1')\n",
        "  tokenizer_bert1 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer1')\n",
        "  segments1 = tokenizer_bert1(text_input1)\n",
        "#   packer1 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 30))\n",
        "  packer1 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs)\n",
        "  encoder_inputs1 = packer1([segments1])\n",
        "  bert_encoder1 = hub.KerasLayer(enc_lnk2, trainable = False, name = 'BERT_encoder1')\n",
        "  out1 = bert_encoder1(encoder_inputs1)\n",
        "  net1 = out1['sequence_output']\n",
        "  model1 = tf.keras.Sequential()\n",
        "  model1.add(layers.LSTM(128,return_sequences=True))\n",
        "  model1.add(layers.LSTM(64,return_sequences=True))\n",
        "  model1.add(layers.LSTM(64))\n",
        "  net1 = model1(net1)\n",
        "\n",
        "#   text_input2 = layers.Input(shape = (), dtype = tf.string, name = 'text2')\n",
        "#   tokenizer_bert2 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer2')\n",
        "#   segments2 = tokenizer_bert2(text_input2)\n",
        "#   packer2 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 5))\n",
        "#   encoder_inputs2 = packer2([segments2])\n",
        "#   bert_encoder2 = hub.KerasLayer(enc_lnk2, trainable = False, name = 'BERT_encoder2')\n",
        "#   out2 = bert_encoder2(encoder_inputs2)\n",
        "#   net2 = out2['sequence_output']\n",
        "#   model2 = tf.keras.Sequential()\n",
        "#   model2.add(layers.LSTM(100,return_sequences=True))\n",
        "#   model2.add(layers.LSTM(40,return_sequences=True))\n",
        "#   model2.add(layers.LSTM(10))\n",
        "#   net2 = model2(net2)\n",
        "\n",
        "  text_input3 = layers.Input(shape = (), dtype = tf.string, name = 'text3')\n",
        "  tokenizer_bert3 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer3')\n",
        "  segments3 = tokenizer_bert3(text_input3)\n",
        "  packer3 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs)\n",
        "#   packer3 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 5))\n",
        "  encoder_inputs3 = packer3([segments3])\n",
        "  bert_encoder3 = hub.KerasLayer(enc_lnk, trainable = False, name = 'BERT_encoder3')\n",
        "  out3 = bert_encoder3(encoder_inputs3)\n",
        "  net3 = out3['sequence_output']\n",
        "  model3 = tf.keras.Sequential()\n",
        "  model3.add(layers.LSTM(128,return_sequences=True))\n",
        "  model3.add(layers.LSTM(64,return_sequences=True))\n",
        "  model3.add(layers.LSTM(64))\n",
        "  net3 = model3(net3)\n",
        "\n",
        "  final_input = layers.Concatenate(axis = -1, name = 'concat_layer')([net1, net3])\n",
        "  dense_1 = layers.Dense(64)\n",
        "  final_input = dense_1(final_input)\n",
        "  dense_2 = layers.Dense(64)\n",
        "  final_input = dense_2(final_input)\n",
        "  dense_last = layers.Dense(20)\n",
        "  final_output = dense_last(final_input)\n",
        "\n",
        "  return Model([text_input1, text_input3], final_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag5eFIlojok3"
      },
      "source": [
        "model = make_classifier_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QKnWuj8jok4",
        "outputId": "aeb15581-8fdd-46bc-ff5c-16f221cf35c1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text1 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text3 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tokenizer1 (KerasLayer)        (None, None, None)   0           ['text1[0][0]']                  \n",
            "                                                                                                  \n",
            " tokenizer3 (KerasLayer)        (None, None, None)   0           ['text3[0][0]']                  \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_type_ids':   0           ['tokenizer1[0][0]']             \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'input_type_ids':   0           ['tokenizer3[0][0]']             \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder1 (KerasLayer)     {'pooled_output': (  4385921     ['keras_layer[0][0]',            \n",
            "                                None, 128),                       'keras_layer[0][1]',            \n",
            "                                 'sequence_output':               'keras_layer[0][2]']            \n",
            "                                 (None, 128, 128),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                128),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 128),                                               \n",
            "                                 (None, 128, 128)]}                                               \n",
            "                                                                                                  \n",
            " BERT_encoder3 (KerasLayer)     {'default': (None,   109482241   ['keras_layer_1[0][0]',          \n",
            "                                768),                             'keras_layer_1[0][1]',          \n",
            "                                 'pooled_output': (               'keras_layer_1[0][2]']          \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)]}                                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 64)           214016      ['BERT_encoder1[0][4]']          \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 64)           541696      ['BERT_encoder3[0][14]']         \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, 128)          0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           4160        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 20)           1300        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 114,637,590\n",
            "Trainable params: 769,428\n",
            "Non-trainable params: 113,868,162\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmWO7bIKjok4"
      },
      "source": [
        "model.compile(optimizer = 'adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUJuR7dYnkEB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBMB7cjEnj14"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "OLfNOg-qnjqd",
        "outputId": "d3261f44-d952-4968-f5b4-2b823204742d"
      },
      "source": [
        "final_data_train['sentences'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'days of age a control group cont remained with the mother in the nest during this time cold subjects were developmentally delayed and had lower body and brain weights than the other three groups into adulthood warm and agit subjects both maternally separated at nest temperature had significant growth delays compared to cont but grew more quickly than cold subjects cold subjects were less AS than the other maternally separated groups and warm and agit groups were more active activity did not differ at or days of age however AD warm subjects were less sensitive and cold subjects were more sensitive to amphetamine as measured by locomotor activity than cont and agit subjects who did not differ from each other the relationship between early stress changes in'"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RcMe1y1Un73F",
        "outputId": "0d7face2-6412-4c75-960d-4546dbd91bae"
      },
      "source": [
        "final_data_train['words'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AS'"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhfoviJjn70W"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzLkdpPpjok4"
      },
      "source": [
        "train1 = np.array(final_data_train['sentences'].tolist())\n",
        "train2 = np.array(final_data_train['words'].tolist())\n",
        "train3 = np.array(final_data_train['sentences'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXp9Lp5V0dSK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvWSrsZn0dPg",
        "outputId": "e4fdde81-7f3c-49ed-b775-5deec95e2287"
      },
      "source": [
        "final_data_train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  8, 17, ..., 11, 17, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h54BgYq0dM9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxtM1CtH0c3R"
      },
      "source": [
        "model.fit(x = [train1, train3], y = final_data_train_labels, epochs = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXGIrBRm0JmH"
      },
      "source": [
        "# model.fit(x = [train1, train3], y = final_data_train_labels, epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEkycjLwjok5"
      },
      "source": [
        "test1 = np.array(final_data_test['sentences'].tolist())\n",
        "test2 = np.array(final_data_test['words'].tolist())\n",
        "test3 = np.array(final_data_test['sentnces'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB8M5-xY0Inr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnWSjMPMjok6"
      },
      "source": [
        "test_pred = model.predict([test1,test3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFlKw6IspbMC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxppZpMdpbJT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNqjiGOpbGR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCbwcde5jok6"
      },
      "source": [
        "final_prediction = []\n",
        "\n",
        "for i in range(0, len(test_pred)):\n",
        "  if (test_pred[i] > 0.5):\n",
        "    final_prediction.append(1)\n",
        "  else:\n",
        "    final_prediction.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "772r1cxKjok6"
      },
      "source": [
        "import tqdm.notebook as tq\n",
        "tp=0\n",
        "fp=0\n",
        "tn=0\n",
        "fn=0\n",
        "for i in tq.tqdm(range(0,len(final_prediction))):\n",
        "    if (final_prediction[i]==1 and final_labels_test[i]==1):\n",
        "      tp=tp+1\n",
        "    elif (final_prediction[i]==0 and final_labels_test[i]==1):\n",
        "      fp=fp+1\n",
        "    elif (final_prediction[i]==1 and final_labels_test[i]==0):\n",
        "      fn=fn+1\n",
        "    elif (final_prediction[i]==0 and final_labels_test[i]==0):\n",
        "      tn=tn+1\n",
        "    \n",
        "precision_nolower = tp/(tp+fp)\n",
        "print(\"Precision = \",precision_nolower)\n",
        "\n",
        "recall_nolower = tp/(tp+fn)\n",
        "print(\"Recall = \",recall_nolower)\n",
        "\n",
        "f1_nolower = (2*precision_nolower*recall_nolower)/(precision_nolower+recall_nolower)\n",
        "print(\"F1 Score = \",f1_nolower)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAxWp8mTjok7"
      },
      "source": [
        "# Training on SciAI and testing on MeDal(test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqFjAga1jok7"
      },
      "source": [
        "data2_train=pd.read_json('https://raw.githubusercontent.com/amirveyseh/AAAI-21-SDU-shared-task-1-AI/master/dataset/train.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWjDwMhljok7"
      },
      "source": [
        "d_train1=[] # not abb\n",
        "d_train1_context=[]\n",
        "d_train_label1=[]\n",
        "\n",
        "d_train2=[] # abb\n",
        "d_train2_context=[]\n",
        "d_train_label2=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQDzOCM6jok7",
        "colab": {
          "referenced_widgets": [
            "e13091bb43d4477386f6ea1e0f4e8329"
          ]
        },
        "outputId": "ccfd4d0e-0fea-479a-a5cb-664cef45cb15"
      },
      "source": [
        "import tqdm.notebook as tq\n",
        "for i in tq.tqdm(range(0,len(data2_train))):\n",
        "    for j in range(0,len(data2_train['tokens'][i])):\n",
        "        if(data2_train['labels'][i][j]!='B-short'):\n",
        "            d_train1.append(str(data2_train['tokens'][i][j]))\n",
        "            left = max(0,j-4)\n",
        "            right = min(len(data2_train['tokens'][i])-1 , j+4)\n",
        "            sen = (\" \").join(data2_train['tokens'][i][left:(right+1)])\n",
        "            d_train1_context.append(sen)\n",
        "            d_train_label1.append(0)\n",
        "        else:\n",
        "            d_train2.append(str(data2_train['tokens'][i][j]))\n",
        "            left = max(0,j-4)\n",
        "            right = min(len(data2_train['tokens'][i])-1 , j+4)\n",
        "            sen = (\" \").join(data2_train['tokens'][i][left:(right+1)])\n",
        "            d_train2_context.append(sen)\n",
        "            d_train_label2.append(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e13091bb43d4477386f6ea1e0f4e8329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14006 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze7xZ9O6jok8",
        "outputId": "17100ee6-ffe5-44df-a247-7909ea7ce00e"
      },
      "source": [
        "print(len(d_train1))\n",
        "print(len(d_train1_context))\n",
        "print(len(d_train_label1))\n",
        "\n",
        "print(len(d_train2))\n",
        "print(len(d_train2_context))\n",
        "print(len(d_train_label2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "428739\n",
            "428739\n",
            "428739\n",
            "24176\n",
            "24176\n",
            "24176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9gb8A6jok8",
        "colab": {
          "referenced_widgets": [
            "8e61916b81634f55a127c92ef20308aa",
            "5fcb17287d6a4706bb1d9258d72ea171",
            "c503a3fb189942f2a499c7007f427ea2"
          ]
        },
        "outputId": "30a55926-208b-4e69-9077-90908dfca751"
      },
      "source": [
        "d_train3=[] # not abb\n",
        "d_train3_context=[]\n",
        "d_train_label3=[]\n",
        "\n",
        "for i in tq.tqdm(range(0,len(d_train1))):\n",
        "    if(i%3 ==0):\n",
        "        d_train3.append(d_train1[i])\n",
        "        d_train3_context.append(d_train1_context[i])\n",
        "        d_train_label3.append(d_train_label1[i])\n",
        "for i in tq.tqdm(range(0,len(d_train2))):\n",
        "    d_train3.append(d_train2[i])\n",
        "    d_train3_context.append(d_train2_context[i])\n",
        "    d_train_label3.append(d_train_label2[i])  \n",
        "    \n",
        "d_train3 = np.array(d_train3)\n",
        "d_train3_context = np.array(d_train3_context)\n",
        "d_train_label3 = np.array(d_train_label3)\n",
        "\n",
        "for i in tq.tqdm(range(0,len(d_train3))):\n",
        "    d_train3[i]=str(d_train3[i])\n",
        "    d_train3_context[i]=str(d_train3_context[i])\n",
        "    d_train_label3[i]=str(d_train_label3[i])\n",
        "    \n",
        "print(d_train3.shape)\n",
        "print(d_train3_context.shape)\n",
        "print(d_train_label3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e61916b81634f55a127c92ef20308aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/428739 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fcb17287d6a4706bb1d9258d72ea171",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/24176 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c503a3fb189942f2a499c7007f427ea2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/167089 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(167089,)\n",
            "(167089,)\n",
            "(167089,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiGxBTGkjok8"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "preprocess_lnk = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "enc_lnk = 'https://tfhub.dev/google/experts/bert/pubmed/2'\n",
        "enc_lnk2 = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n",
        "\n",
        "bert_preprocessor = hub.load(preprocess_lnk)\n",
        "\n",
        "def make_classifier_model2():\n",
        "  text_input1 = layers.Input(shape = (), dtype = tf.string, name = 'text1')\n",
        "  tokenizer_bert1 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer1')\n",
        "  segments1 = tokenizer_bert1(text_input1)\n",
        "  packer1 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 30))\n",
        "  encoder_inputs1 = packer1([segments1])\n",
        "  bert_encoder1 = hub.KerasLayer(enc_lnk2, trainable = False, name = 'BERT_encoder1')\n",
        "  out1 = bert_encoder1(encoder_inputs1)\n",
        "  net1 = out1['sequence_output']\n",
        "  model1 = tf.keras.Sequential()\n",
        "  model1.add(layers.LSTM(100,return_sequences=True))\n",
        "  model1.add(layers.LSTM(40,return_sequences=True))\n",
        "  model1.add(layers.LSTM(10))\n",
        "  net1 = model1(net1)\n",
        "\n",
        "  text_input2 = layers.Input(shape = (), dtype = tf.string, name = 'text2')\n",
        "  tokenizer_bert2 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer2')\n",
        "  segments2 = tokenizer_bert2(text_input2)\n",
        "  packer2 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 5))\n",
        "  encoder_inputs2 = packer2([segments2])\n",
        "  bert_encoder2 = hub.KerasLayer(enc_lnk2, trainable = False, name = 'BERT_encoder2')\n",
        "  out2 = bert_encoder2(encoder_inputs2)\n",
        "  net2 = out2['sequence_output']\n",
        "  model2 = tf.keras.Sequential()\n",
        "  model2.add(layers.LSTM(100,return_sequences=True))\n",
        "  model2.add(layers.LSTM(40,return_sequences=True))\n",
        "  model2.add(layers.LSTM(10))\n",
        "  net2 = model2(net2)\n",
        "\n",
        "  text_input3 = layers.Input(shape = (), dtype = tf.string, name = 'text3')\n",
        "  tokenizer_bert3 = hub.KerasLayer(bert_preprocessor.tokenize, name = 'tokenizer3')\n",
        "  segments3 = tokenizer_bert3(text_input3)\n",
        "  packer3 = hub.KerasLayer(bert_preprocessor.bert_pack_inputs, arguments = dict(seq_length = 5))\n",
        "  encoder_inputs3 = packer3([segments3])\n",
        "  bert_encoder3 = hub.KerasLayer(enc_lnk, trainable = False, name = 'BERT_encoder3')\n",
        "  out3 = bert_encoder3(encoder_inputs3)\n",
        "  net3 = out3['sequence_output']\n",
        "  model3 = tf.keras.Sequential()\n",
        "  model3.add(layers.LSTM(100,return_sequences=True))\n",
        "  model3.add(layers.LSTM(40,return_sequences=True))\n",
        "  model3.add(layers.LSTM(10))\n",
        "  net3 = model3(net3)\n",
        "\n",
        "  final_input = layers.Concatenate(axis = -1, name = 'concat_layer')([net1, net2, net3])\n",
        "  dense_last = layers.Dense(1, activation = 'sigmoid')\n",
        "  final_output = dense_last(final_input)\n",
        "\n",
        "  return Model([text_input1, text_input2, text_input3], final_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBDZOencjok9"
      },
      "source": [
        "model2 = make_classifier_model2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXsQDTD3jok9",
        "outputId": "a5dfd145-c693-488c-f315-d020e29528bc"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text1 (InputLayer)              [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text2 (InputLayer)              [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text3 (InputLayer)              [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tokenizer1 (KerasLayer)         (None, None, None)   0           text1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tokenizer2 (KerasLayer)         (None, None, None)   0           text2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tokenizer3 (KerasLayer)         (None, None, None)   0           text3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      {'input_mask': (None 0           tokenizer1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_4 (KerasLayer)      {'input_mask': (None 0           tokenizer2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_5 (KerasLayer)      {'input_mask': (None 0           tokenizer3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder1 (KerasLayer)      {'encoder_outputs':  4385921     keras_layer_3[0][0]              \n",
            "                                                                 keras_layer_3[0][1]              \n",
            "                                                                 keras_layer_3[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder2 (KerasLayer)      {'encoder_outputs':  4385921     keras_layer_4[0][0]              \n",
            "                                                                 keras_layer_4[0][1]              \n",
            "                                                                 keras_layer_4[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "BERT_encoder3 (KerasLayer)      {'encoder_outputs':  109482241   keras_layer_5[0][0]              \n",
            "                                                                 keras_layer_5[0][1]              \n",
            "                                                                 keras_layer_5[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 10)           116200      BERT_encoder1[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 10)           116200      BERT_encoder2[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 10)           372200      BERT_encoder3[0][14]             \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, 30)           0           sequential_3[0][0]               \n",
            "                                                                 sequential_4[0][0]               \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            31          concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 118,858,714\n",
            "Trainable params: 604,631\n",
            "Non-trainable params: 118,254,083\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW5NUQqLjok9",
        "outputId": "3d590ae3-4fb3-4639-df79-7d07e0975a50"
      },
      "source": [
        "type(d_train3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIolTQ-3jok9"
      },
      "source": [
        "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icjBkzl_jok-"
      },
      "source": [
        "d_train3_cpy = d_train3.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlfxOVBcjok-",
        "outputId": "931f1eb2-ef24-4faa-e6e4-6006458ce597"
      },
      "source": [
        "print(len(d_train3))\n",
        "print(len(d_train3_cpy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167089\n",
            "167089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euCqzpVKjok-",
        "outputId": "7c70afff-f6c6-4239-b8ef-fb7ce18d4d54"
      },
      "source": [
        "model2.fit(x = [d_train3_context,d_train3,d_train3_cpy], y = d_train_label3 , epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5222/5222 [==============================] - 678s 127ms/step - loss: 0.0760 - precision_1: 0.9057 - recall_1: 0.9173\n",
            "Epoch 2/5\n",
            "5222/5222 [==============================] - 661s 127ms/step - loss: 0.0581 - precision_1: 0.9243 - recall_1: 0.9440\n",
            "Epoch 3/5\n",
            "5222/5222 [==============================] - 661s 127ms/step - loss: 0.0531 - precision_1: 0.9288 - recall_1: 0.9488\n",
            "Epoch 4/5\n",
            "5222/5222 [==============================] - 660s 126ms/step - loss: 0.0498 - precision_1: 0.9328 - recall_1: 0.9538\n",
            "Epoch 5/5\n",
            "5222/5222 [==============================] - 660s 126ms/step - loss: 0.0476 - precision_1: 0.9355 - recall_1: 0.9571\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ef839bfd6a0>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCS6fm9Ljok-"
      },
      "source": [
        "# test_pred2 = model.predict([test1,test2,test3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92YTnPDNjok_"
      },
      "source": [
        "# final_prediction2 = []\n",
        "\n",
        "# for i in range(0, len(test_pred2)):\n",
        "#   if (test_pred2[i] > 0.5):\n",
        "#     final_prediction2.append(1)\n",
        "#   else:\n",
        "#     final_prediction2.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Tl1UqZjok_",
        "colab": {
          "referenced_widgets": [
            "57b24f59c1b24cd0b353be91497eadac"
          ]
        },
        "outputId": "9c9e308b-4982-45ff-a036-a1d7d0ab9070"
      },
      "source": [
        "# import tqdm.notebook as tq\n",
        "# tp=0\n",
        "# fp=0\n",
        "# tn=0\n",
        "# fn=0\n",
        "# for i in tq.tqdm(range(0,len(final_prediction2))):\n",
        "#     if (final_prediction2[i]==1 and final_labels_test[i]==1):\n",
        "#       tp=tp+1\n",
        "#     elif (final_prediction2[i]==0 and final_labels_test[i]==1):\n",
        "#       fp=fp+1\n",
        "#     elif (final_prediction2[i]==1 and final_labels_test[i]==0):\n",
        "#       fn=fn+1\n",
        "#     elif (final_prediction2[i]==0 and final_labels_test[i]==0):\n",
        "#       tn=tn+1\n",
        "    \n",
        "# precision_nolower = tp/(tp+fp)\n",
        "# print(\"Precision = \",precision_nolower)\n",
        "\n",
        "# recall_nolower = tp/(tp+fn)\n",
        "# print(\"Recall = \",recall_nolower)\n",
        "\n",
        "# f1_nolower = (2*precision_nolower*recall_nolower)/(precision_nolower+recall_nolower)\n",
        "# print(\"F1 Score = \",f1_nolower)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57b24f59c1b24cd0b353be91497eadac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/177242 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.9041533546325878\n",
            "Recall =  0.8141542002301496\n",
            "F1 Score =  0.8567968513472601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GlCrDDLjok_"
      },
      "source": [
        "final_data.to_csv('final_data_abb_notebook2.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A36nZUjAjok_"
      },
      "source": [
        "test_pred2 = model2.predict([test1,test2,test3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xeMuLJqjolA"
      },
      "source": [
        "final_prediction2 = []\n",
        "\n",
        "for i in range(0, len(test_pred2)):\n",
        "  if (test_pred2[i] > 0.5):\n",
        "    final_prediction2.append(1)\n",
        "  else:\n",
        "    final_prediction2.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2H_7TwgjolA",
        "colab": {
          "referenced_widgets": [
            "6cecaefef62743a7aa4d56a265fd3f2e"
          ]
        },
        "outputId": "d8021749-7e60-4cd5-87b3-8724591eb0cc"
      },
      "source": [
        "import tqdm.notebook as tq\n",
        "tp=0\n",
        "fp=0\n",
        "tn=0\n",
        "fn=0\n",
        "for i in tq.tqdm(range(0,len(final_prediction2))):\n",
        "    if (final_prediction2[i]==1 and final_labels_test[i]==1):\n",
        "      tp=tp+1\n",
        "    elif (final_prediction2[i]==0 and final_labels_test[i]==1):\n",
        "      fp=fp+1\n",
        "    elif (final_prediction2[i]==1 and final_labels_test[i]==0):\n",
        "      fn=fn+1\n",
        "    elif (final_prediction2[i]==0 and final_labels_test[i]==0):\n",
        "      tn=tn+1\n",
        "    \n",
        "precision_nolower = tp/(tp+fp)\n",
        "print(\"Precision = \",precision_nolower)\n",
        "\n",
        "recall_nolower = tp/(tp+fn)\n",
        "print(\"Recall = \",recall_nolower)\n",
        "\n",
        "f1_nolower = (2*precision_nolower*recall_nolower)/(precision_nolower+recall_nolower)\n",
        "print(\"F1 Score = \",f1_nolower)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cecaefef62743a7aa4d56a265fd3f2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/177242 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.899520766773163\n",
            "Recall =  0.48140548858681714\n",
            "F1 Score =  0.6271648939132372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irj3bMtWjolA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUYQADMloMUb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}